---
title: "Data"
output: rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{Data}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Background

There are four types of data that are tied to all of the workflows: tagging data, detection data, deployment data, and shed tag/migratory fate data.  All data for the database is contained in the `YB Telemetry Study/YB_SQL_BaseTables` directory on Google Drive. 

#### General data workflow

1. Update `Deployments.xlsx` after receiver downloads or deployments happen.
2. Update `Chinook.xlsx` and `Tags.xlsx` after tagging takes place.
3. Update `Sheds.xlsx` throughout the tagging season and as analysis discovers more shed/mortality tags.
4. Save to Google Drive.
5. When you are ready to update the database (i.e. to begin the `Database` workflow), download a full copy of the `YB Telemetry Study` folder to the computer you'll be updating the database with, and keep the folder's default download name, which should include the date of download.

#### Things to remember for all data and files:

1. The column names of base spreadsheets should not be changed without consultation, as much of the database building and cleaning code depends on these variable names.
2. Data from past detection years is not necessarily housed or named in the same way as it will be going forward.
3. All times should be in Pacific Standard Time, not clock time, and the format is YYYY-DD-MM HH:MM:SS.  When entering dates and times in Excel, either store the column as text/general format (preferred), or choose this custom format from the Date or Time format menu.
4. Update all editable datasheets ON Google Drive using Google Sheets.  This ensures a kind of version control, and prevents having lots of copies of the data lying around.


### 1. Deployments

All information about receiver deployments that is used by the `ybt` package is stored in the "Deployments.xlsx" spreadsheet, currently hosted on Google Drive (as of August 2019).  This forms the basis of the `deployments` table in the `yb_database.sqlite` database, which can be viewed by calling:

```{r, echo=TRUE, eval=FALSE}
library(dplyr)
db = RSQLite::dbConnect(RSQLite::SQLite(), "yb_database.sqlite") # change to your correct relative path

deps = tbl(db, "deployments") %>% 
  collect()

str(deps[1:5, ])
```

```{r, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}

pdeps <- structure(list(Location = c("Base of the confluence southeast", 
"Base of the confluence southeast", "Base of the confluence southeast", 
"Base of the confluence southeast", "Base of the confluence southeast"
), StationAbbOld = c("BCE2", "BCE2", "BCE2", "BCE2", "BCE2"), 
    Station = c("YBCSSE", "YBCSSE", "YBCSSE", "YBCSSE", "YBCSSE"
    ), Receiver = c(106092L, 106092L, 106092L, 106092L, 106092L
    ), DetectionYear = c(2012L, 2012L, 2013L, 2013L, 2014L), 
    DeploymentStart = c("2012-12-18 12:14:55", "2013-05-30 11:52:00", 
    "2013-10-24 10:03:00", "2014-05-15 08:44:44", "2014-08-22 09:25:00"
    ), DeploymentEnd = c("2013-05-30 11:34:00", "2013-10-24 09:56:00", 
    "2014-05-15 07:59:00", "2014-08-22 09:09:15", "2015-01-28 11:59:00"
    ), VRLDate = c("2013-05-30", "2013-10-24", "2014-05-15", 
    "2014-08-22", "2015-01-28"), DeploymentNotes = c("new receiver", 
    "brought back up to re-initialize because VUE froze; added 180khz", 
    "had trouble downloading on Ryan's comp; downloaded to tablet. Left 180khz for range tests", 
    "Upgraded firmware on pull", "12pm tester tag 8K+ dets.  Left data on.  Battery reading 3.25 V, lower than others.  Replaced cable splice."
    ), VRLNotes = c(NA_character_, NA_character_, NA_character_, 
    NA_character_, NA_character_)), class = c("tbl_df", "tbl", 
"data.frame"), row.names = c(NA, -5L))

str(pdeps)

```

The deployments table serves two essential functions:

 1) It ensures that every detection in the Yolo Bypass detection database has a "home."  That is, that no detections exist outside of the deployment window (`DeploymentStart` - `DeploymentEnd`) of some receiver within the array.

 2) It is the official record of vrl detection year membership, i.e. what detection year a given vrl belongs to, because detection year membership is determined by the `DeploymentStart` date of that vrl's receiver.
 
These two roles are very important, and thus recording the `DeploymentStart` date, in particular, is very important at the data stage.

####  Data procedure for deployments:

 - Follow the instructions in the Downloads SOP.
 - Whenever a receiver is deployed for the first time or downloaded at its station, open `Deployments.xlsx` it in Google Sheets, create a blank row under the receiver location in question, and fill out the fields in the row.
 
####  Things to remember about deployment data:

1. The Station names MUST match the official Station names used in the cleaning scripts.  They are correct on the spreadsheet - just make sure they match when you're entering a new line.

2. Each row of the spreadsheet must have a `DeploymentStart` date/time AND a `DeploymentEnd` time. In practice, what this means is that there may be `NAs` in many `DeploymentEnd` fields, especially after the first round of downloads for a detection year. 

3. A deployment starts when the receiver is actually submerged in the field for the first time, or when it is submerged after having just been downloaded.  A deployment ENDs when the receiver is pulled out of the water before being downloaded, or when it is pulled for the season, or when it is swapped out with another receiver, i.e., it ends when that receiver cannot record any more detections for that deployment period.

## 2. Tags

Similar to the `deployments` table, there is a `tags` table in the `yb_database.sqlite` database. This table includes metadata types that are common to both white sturgeon and Chinook salmon.  Whenever new tagged fish are released, it is important to update the `Tags.xlsx` file on Google Drive.

In addition to `Tags.xlsx`, the `Tags/` directory also contains a spreadsheet `Chinook.xlsx`, which is specific to Chinook salmon tagging metadata.  This spreadsheet forms the `chn` table in the database, and includes the particulars of surgery, RAMP scores, capture times, etc, and should be updated separately.  A similar record may be created for white sturgeon in the future.

#### Things to remember about tag data:

1. When a tag is recovered and redeployed on a second fish in the same season, make sure to record its second deployment in the database tables (`tags` and `chn`) under a made-up numeric TagID (i.e. `7777`), with the original (actual) transmitter code in the `Comments` field.  These tags require special handling in the analysis workflow.


## 3. Detections

The detections data workflow is a bit more involved, and so it is covered in the `Database` vignette.

## 4. Shed tags

The identification of shed tags is an ongoing process.  The `Sheds.xlsx` spreadsheet in the `YB_SQL_BaseTables` directory is just a record of these tags - update it online as you find them or receive information about fish fates, but nothing in the current analysis workflow depends on this spreadsheet because it's in flux.
